{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T09:53:05.816168Z",
     "start_time": "2025-12-14T09:47:15.756228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "class DepressionModelTrainer:\n",
    "    def __init__(self, data_path, target_column='Depression', output_dir='models'):\n",
    "        \"\"\"\n",
    "        Initialize the model trainer\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to preprocessed data CSV\n",
    "            target_column: Name of target variable\n",
    "            output_dir: Directory to save models and results\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.target_column = target_column\n",
    "        self.output_dir = output_dir\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        self.feature_names = None\n",
    "\n",
    "        # Create output directories\n",
    "        self._setup_directories()\n",
    "\n",
    "    def _setup_directories(self):\n",
    "        \"\"\"Create necessary output directories\"\"\"\n",
    "        dirs = [\n",
    "            self.output_dir,\n",
    "            f'{self.output_dir}/visualizations',\n",
    "            f'{self.output_dir}/reports'\n",
    "        ]\n",
    "        for dir_path in dirs:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "        print(\"âœ“ Output directories created\")\n",
    "\n",
    "    def load_preprocessed_data(self):\n",
    "        \"\"\"Load the preprocessed data\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"LOADING PREPROCESSED DATA\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        if not os.path.exists(self.data_path):\n",
    "            print(f\"âœ— ERROR: File not found at {self.data_path}\")\n",
    "            print(\"   Please run the preprocessing script first.\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            self.data = pd.read_csv(self.data_path)\n",
    "            print(f\"âœ“ Data loaded successfully\")\n",
    "            print(f\"  Shape: {self.data.shape}\")\n",
    "            print(f\"  Columns: {len(self.data.columns)}\")\n",
    "\n",
    "            # Check if target column exists\n",
    "            if self.target_column not in self.data.columns:\n",
    "                print(f\"\\nâœ— ERROR: Target column '{self.target_column}' not found!\")\n",
    "                print(f\"  Available columns: {list(self.data.columns)[:5]}...\")\n",
    "                return False\n",
    "\n",
    "            # Ensure target is integer\n",
    "            self.data[self.target_column] = self.data[self.target_column].astype(int)\n",
    "\n",
    "            # Verify binary classification\n",
    "            unique_values = sorted(self.data[self.target_column].unique())\n",
    "            if len(unique_values) != 2:\n",
    "                print(f\"\\nâœ— ERROR: Expected binary target, found {len(unique_values)} classes: {unique_values}\")\n",
    "                return False\n",
    "\n",
    "            if set(unique_values) != {0, 1}:\n",
    "                print(f\"\\nâš ï¸  WARNING: Target values are {unique_values}, expected [0, 1]\")\n",
    "                print(\"   Remapping to binary...\")\n",
    "                mapping = {unique_values[0]: 0, unique_values[1]: 1}\n",
    "                self.data[self.target_column] = self.data[self.target_column].map(mapping)\n",
    "\n",
    "            # Display distribution\n",
    "            print(f\"\\n  Target Distribution ({self.target_column}):\")\n",
    "            value_counts = self.data[self.target_column].value_counts().sort_index()\n",
    "            for val, count in value_counts.items():\n",
    "                label = \"Healthy (No Depression)\" if val == 0 else \"Depressed\"\n",
    "                percentage = (count / len(self.data)) * 100\n",
    "                print(f\"    {label} ({val}): {count:,} samples ({percentage:.1f}%)\")\n",
    "\n",
    "            # Check for class imbalance\n",
    "            minority_class_pct = min(value_counts.values) / len(self.data) * 100\n",
    "            if minority_class_pct < 20:\n",
    "                print(f\"\\n  âš ï¸  Class imbalance detected ({minority_class_pct:.1f}% minority class)\")\n",
    "                print(\"     Using stratified split and weighted metrics\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— ERROR loading data: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    def prepare_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"Prepare features and target, split into train/test\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PREPARING DATA FOR TRAINING\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        try:\n",
    "            # Separate features and target\n",
    "            self.X = self.data.drop(columns=[self.target_column])\n",
    "            self.y = self.data[self.target_column]\n",
    "            self.feature_names = self.X.columns.tolist()\n",
    "\n",
    "            print(f\"  Features: {self.X.shape[1]} columns\")\n",
    "            print(f\"  Samples: {len(self.X):,}\")\n",
    "\n",
    "            # Check for any remaining issues\n",
    "            if self.X.isnull().any().any():\n",
    "                print(f\"  âš ï¸  WARNING: Found {self.X.isnull().sum().sum()} missing values in features\")\n",
    "                print(\"     Filling with 0...\")\n",
    "                self.X = self.X.fillna(0)\n",
    "\n",
    "            if np.isinf(self.X.values).any():\n",
    "                print(f\"  âš ï¸  WARNING: Found infinite values in features\")\n",
    "                print(\"     Replacing with large finite values...\")\n",
    "                self.X = self.X.replace([np.inf, -np.inf], [1e10, -1e10])\n",
    "\n",
    "            # Split data with stratification (maintains class balance)\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                self.X, self.y, \n",
    "                test_size=test_size, \n",
    "                random_state=random_state, \n",
    "                stratify=self.y\n",
    "            )\n",
    "\n",
    "            print(f\"\\n  Train/Test Split:\")\n",
    "            print(f\"    Train set: {len(self.X_train):,} samples ({(1-test_size)*100:.0f}%)\")\n",
    "            print(f\"    Test set:  {len(self.X_test):,} samples ({test_size*100:.0f}%)\")\n",
    "\n",
    "            # Verify stratification worked\n",
    "            print(f\"\\n  Train distribution:\")\n",
    "            train_counts = self.y_train.value_counts().sort_index()\n",
    "            for val, count in train_counts.items():\n",
    "                pct = (count / len(self.y_train)) * 100\n",
    "                print(f\"    Class {val}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "            print(f\"\\n  Test distribution:\")\n",
    "            test_counts = self.y_test.value_counts().sort_index()\n",
    "            for val, count in test_counts.items():\n",
    "                pct = (count / len(self.y_test)) * 100\n",
    "                print(f\"    Class {val}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— ERROR preparing data: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize multiple ML models with optimized hyperparameters\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"INITIALIZING MODELS\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        self.models = {\n",
    "            'Logistic Regression': LogisticRegression(\n",
    "                max_iter=1000, \n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                solver='lbfgs'\n",
    "            ),\n",
    "            'Random Forest': RandomForestClassifier(\n",
    "                n_estimators=100, \n",
    "                random_state=42, \n",
    "                max_depth=15,\n",
    "                min_samples_split=10,\n",
    "                min_samples_leaf=5,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(\n",
    "                n_estimators=100, \n",
    "                random_state=42, \n",
    "                max_depth=5,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8\n",
    "            ),\n",
    "            'Support Vector Machine': SVC(\n",
    "                probability=True, \n",
    "                random_state=42, \n",
    "                kernel='rbf',\n",
    "                class_weight='balanced',\n",
    "                C=1.0\n",
    "            ),\n",
    "            'K-Nearest Neighbors': KNeighborsClassifier(\n",
    "                n_neighbors=7,\n",
    "                weights='distance',\n",
    "                metric='euclidean'\n",
    "            ),\n",
    "            'Decision Tree': DecisionTreeClassifier(\n",
    "                random_state=42, \n",
    "                max_depth=15,\n",
    "                min_samples_split=10,\n",
    "                min_samples_leaf=5,\n",
    "                class_weight='balanced'\n",
    "            ),\n",
    "            'Naive Bayes': GaussianNB()\n",
    "        }\n",
    "\n",
    "        print(f\"  Initialized {len(self.models)} models:\")\n",
    "        for name in self.models.keys():\n",
    "            print(f\"    â€¢ {name}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def train_and_evaluate_models(self):\n",
    "        \"\"\"Train and evaluate all models with cross-validation\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRAINING AND EVALUATING MODELS\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"MODEL: {model_name}\")\n",
    "            print(f\"{'='*70}\")\n",
    "\n",
    "            try:\n",
    "                # Train model\n",
    "                print(\"Training...\")\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "\n",
    "                # Make predictions\n",
    "                y_pred_test = model.predict(self.X_test)\n",
    "                y_pred_train = model.predict(self.X_train)\n",
    "\n",
    "                # Get probability predictions (for ROC curve)\n",
    "                y_prob_test = None\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_prob_test = model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "                # Calculate metrics\n",
    "                train_accuracy = accuracy_score(self.y_train, y_pred_train)\n",
    "                test_accuracy = accuracy_score(self.y_test, y_pred_test)\n",
    "\n",
    "                # Use weighted average for imbalanced datasets\n",
    "                precision = precision_score(self.y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "                recall = recall_score(self.y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "                f1 = f1_score(self.y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "                # Calculate per-class metrics\n",
    "                precision_per_class = precision_score(self.y_test, y_pred_test, average=None, zero_division=0)\n",
    "                recall_per_class = recall_score(self.y_test, y_pred_test, average=None, zero_division=0)\n",
    "                f1_per_class = f1_score(self.y_test, y_pred_test, average=None, zero_division=0)\n",
    "\n",
    "                # ROC-AUC score\n",
    "                roc_auc = None\n",
    "                if y_prob_test is not None:\n",
    "                    try:\n",
    "                        roc_auc = roc_auc_score(self.y_test, y_prob_test)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Cross-validation score (CRITICAL FOR ROBUSTNESS)\n",
    "                print(\"Performing 5-Fold Cross-Validation...\")\n",
    "                cv_scores = None\n",
    "                cv_mean = None\n",
    "                cv_std = None\n",
    "                try:\n",
    "                    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "                    cv_scores = cross_val_score(model, self.X_train, self.y_train, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "                    cv_mean = cv_scores.mean()\n",
    "                    cv_std = cv_scores.std()\n",
    "                except Exception as e:\n",
    "                    print(f\"  âš ï¸  Cross-validation failed: {str(e)[:50]}\")\n",
    "\n",
    "                # Confusion matrix\n",
    "                cm = confusion_matrix(self.y_test, y_pred_test)\n",
    "\n",
    "                # Store results\n",
    "                self.results[model_name] = {\n",
    "                    'model': model,\n",
    "                    'train_accuracy': train_accuracy,\n",
    "                    'test_accuracy': test_accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1,\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'cv_scores': cv_scores,\n",
    "                    'cv_mean': cv_mean,\n",
    "                    'cv_std': cv_std,\n",
    "                    'overfit_gap': train_accuracy - test_accuracy,\n",
    "                    'y_pred_test': y_pred_test,\n",
    "                    'y_prob_test': y_prob_test,\n",
    "                    'precision_per_class': precision_per_class,\n",
    "                    'recall_per_class': recall_per_class,\n",
    "                    'f1_per_class': f1_per_class,\n",
    "                    'confusion_matrix': cm\n",
    "                }\n",
    "\n",
    "                # PRINT DETAILED RESULTS\n",
    "                print(f\"\\nğŸ“Š PERFORMANCE METRICS:\")\n",
    "                print(f\"{'â”€'*70}\")\n",
    "                print(f\"  Train Accuracy:  {train_accuracy*100:6.2f}%\")\n",
    "                print(f\"  Test Accuracy:   {test_accuracy*100:6.2f}%\")\n",
    "                print(f\"  Precision:       {precision*100:6.2f}%\")\n",
    "                print(f\"  Recall:          {recall*100:6.2f}%\")\n",
    "                print(f\"  F1-Score:        {f1*100:6.2f}%\")\n",
    "                if roc_auc:\n",
    "                    print(f\"  ROC-AUC:         {roc_auc*100:6.2f}%\")\n",
    "                if cv_mean is not None:\n",
    "                    print(f\"  CV F1-Score:     {cv_mean*100:6.2f}% (Â±{cv_std*100:4.2f}%)\")\n",
    "                    print(f\"  CV Scores:       {[f'{s*100:.2f}%' for s in cv_scores]}\")\n",
    "                print(f\"  Overfit Gap:     {(train_accuracy - test_accuracy)*100:6.2f}%\")\n",
    "                \n",
    "                print(f\"\\nğŸ“ˆ PER-CLASS METRICS:\")\n",
    "                print(f\"{'â”€'*70}\")\n",
    "                print(f\"  Class 0 (Healthy):\")\n",
    "                print(f\"    Precision: {precision_per_class[0]*100:6.2f}%\")\n",
    "                print(f\"    Recall:    {recall_per_class[0]*100:6.2f}%\")\n",
    "                print(f\"    F1-Score:  {f1_per_class[0]*100:6.2f}%\")\n",
    "                print(f\"\\n  Class 1 (Depressed):\")\n",
    "                print(f\"    Precision: {precision_per_class[1]*100:6.2f}%\")\n",
    "                print(f\"    Recall:    {recall_per_class[1]*100:6.2f}%\")\n",
    "                print(f\"    F1-Score:  {f1_per_class[1]*100:6.2f}%\")\n",
    "                \n",
    "                print(f\"\\nğŸ¯ CONFUSION MATRIX:\")\n",
    "                print(f\"{'â”€'*70}\")\n",
    "                print(f\"                Predicted\")\n",
    "                print(f\"              Healthy  Depressed\")\n",
    "                print(f\"    Healthy      {cm[0][0]:4d}     {cm[0][1]:4d}\")\n",
    "                print(f\"    Depressed    {cm[1][0]:4d}     {cm[1][1]:4d}\")\n",
    "                print()\n",
    "\n",
    "                # Warning for overfitting\n",
    "                if (train_accuracy - test_accuracy) > 0.1:\n",
    "                    print(f\"âš ï¸  WARNING: Possible overfitting detected!\")\n",
    "                    print(f\"   Train-Test gap: {(train_accuracy - test_accuracy)*100:.2f}%\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— ERROR training {model_name}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "        if not self.results:\n",
    "            print(\"\\nâœ— ERROR: No models trained successfully!\")\n",
    "            return False\n",
    "\n",
    "        print(f\"\\nâœ“ Successfully trained {len(self.results)}/{len(self.models)} models\")\n",
    "        return True\n",
    "\n",
    "    def compare_models(self):\n",
    "        \"\"\"Compare all models and find the best one\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"FINAL MODEL COMPARISON\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "        # Create comparison dataframe\n",
    "        comparison_data = []\n",
    "        for model_name, results in self.results.items():\n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Test Accuracy': results['test_accuracy'],\n",
    "                'F1-Score': results['f1_score'],\n",
    "                'Precision': results['precision'],\n",
    "                'Recall': results['recall'],\n",
    "                'ROC-AUC': results['roc_auc'] if results['roc_auc'] else 0,\n",
    "                'CV F1-Score': results['cv_mean'] if results['cv_mean'] else 0,\n",
    "                'CV Std': results['cv_std'] if results['cv_std'] else 0,\n",
    "                'Overfit Gap': results['overfit_gap']\n",
    "            }\n",
    "            comparison_data.append(row)\n",
    "\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "        # Sort by F1-Score (better for medical data than accuracy)\n",
    "        comparison_df = comparison_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "        # Print formatted table\n",
    "        print(f\"{'Model':<25} {'Accuracy':>10} {'F1-Score':>10} {'Precision':>10} {'Recall':>10} {'CV F1':>10}\")\n",
    "        print(\"â”€\" * 95)\n",
    "        for _, row in comparison_df.iterrows():\n",
    "            print(f\"{row['Model']:<25} {row['Test Accuracy']*100:>9.2f}% {row['F1-Score']*100:>9.2f}% \"\n",
    "                  f\"{row['Precision']*100:>9.2f}% {row['Recall']*100:>9.2f}% {row['CV F1-Score']*100:>9.2f}%\")\n",
    "\n",
    "        # Find best model\n",
    "        self.best_model_name = comparison_df.iloc[0]['Model']\n",
    "        self.best_model = self.results[self.best_model_name]['model']\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ† BEST MODEL: {self.best_model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        best_res = self.results[self.best_model_name]\n",
    "        print(f\"  Test Accuracy:   {best_res['test_accuracy']*100:.2f}%\")\n",
    "        print(f\"  F1-Score:        {best_res['f1_score']*100:.2f}%\")\n",
    "        print(f\"  Precision:       {best_res['precision']*100:.2f}%\")\n",
    "        print(f\"  Recall:          {best_res['recall']*100:.2f}%\")\n",
    "        if best_res['roc_auc']:\n",
    "            print(f\"  ROC-AUC:         {best_res['roc_auc']*100:.2f}%\")\n",
    "        if best_res['cv_mean']:\n",
    "            print(f\"  CV F1-Score:     {best_res['cv_mean']*100:.2f}% (Â±{best_res['cv_std']*100:.2f}%)\")\n",
    "        print()\n",
    "\n",
    "        # Save comparison to CSV\n",
    "        comparison_df.to_csv(f'{self.output_dir}/model_comparison.csv', index=False)\n",
    "        print(f\"âœ“ Comparison saved to: {self.output_dir}/model_comparison.csv\\n\")\n",
    "\n",
    "        return comparison_df\n",
    "\n",
    "    def generate_detailed_report(self):\n",
    "        \"\"\"Generate detailed classification report for best model\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GENERATING DETAILED REPORT\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        best_results = self.results[self.best_model_name]\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(\n",
    "            self.y_test, \n",
    "            best_results['y_pred_test'],\n",
    "            target_names=['Healthy', 'Depressed'],\n",
    "            digits=4\n",
    "        )\n",
    "\n",
    "        print(f\"\\nClassification Report for {self.best_model_name}:\")\n",
    "        print(\"â”€\" * 70)\n",
    "        print(report)\n",
    "\n",
    "        # Save to file\n",
    "        report_path = f'{self.output_dir}/reports/classification_report.txt'\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(f\"Classification Report - {self.best_model_name}\\n\")\n",
    "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            f.write(report)\n",
    "            f.write(f\"\\n\\nConfusion Matrix:\\n\")\n",
    "            f.write(str(best_results['confusion_matrix']))\n",
    "            if best_results['cv_mean']:\n",
    "                f.write(f\"\\n\\nCross-Validation F1-Scores:\\n\")\n",
    "                f.write(f\"Mean: {best_results['cv_mean']:.4f}\\n\")\n",
    "                f.write(f\"Std:  {best_results['cv_std']:.4f}\\n\")\n",
    "                f.write(f\"Individual Scores: {best_results['cv_scores']}\\n\")\n",
    "\n",
    "        print(f\"âœ“ Report saved to: {report_path}\")\n",
    "\n",
    "        # Save comprehensive metrics as JSON\n",
    "        metrics = {\n",
    "            'model_name': self.best_model_name,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'test_accuracy': float(best_results['test_accuracy']),\n",
    "            'train_accuracy': float(best_results['train_accuracy']),\n",
    "            'f1_score': float(best_results['f1_score']),\n",
    "            'precision': float(best_results['precision']),\n",
    "            'recall': float(best_results['recall']),\n",
    "            'roc_auc': float(best_results['roc_auc']) if best_results['roc_auc'] else None,\n",
    "            'cv_f1_mean': float(best_results['cv_mean']) if best_results['cv_mean'] else None,\n",
    "            'cv_f1_std': float(best_results['cv_std']) if best_results['cv_std'] else None,\n",
    "            'cv_f1_scores': [float(s) for s in best_results['cv_scores']] if best_results['cv_scores'] is not None else None,\n",
    "            'overfit_gap': float(best_results['overfit_gap']),\n",
    "            'confusion_matrix': best_results['confusion_matrix'].tolist(),\n",
    "            'per_class_metrics': {\n",
    "                'healthy': {\n",
    "                    'precision': float(best_results['precision_per_class'][0]),\n",
    "                    'recall': float(best_results['recall_per_class'][0]),\n",
    "                    'f1': float(best_results['f1_per_class'][0])\n",
    "                },\n",
    "                'depressed': {\n",
    "                    'precision': float(best_results['precision_per_class'][1]),\n",
    "                    'recall': float(best_results['recall_per_class'][1]),\n",
    "                    'f1': float(best_results['f1_per_class'][1])\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        metrics_path = f'{self.output_dir}/best_model_metrics.json'\n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "        print(f\"âœ“ Metrics saved to: {metrics_path}\\n\")\n",
    "\n",
    "    def plot_visualizations(self):\n",
    "        \"\"\"Generate comprehensive visualizations\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GENERATING VISUALIZATIONS\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        viz_dir = f'{self.output_dir}/visualizations'\n",
    "\n",
    "        # 1. Confusion Matrix for Best Model\n",
    "        try:\n",
    "            best_results = self.results[self.best_model_name]\n",
    "            cm = best_results['confusion_matrix']\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(\n",
    "                cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Healthy', 'Depressed'],\n",
    "                yticklabels=['Healthy', 'Depressed'],\n",
    "                cbar_kws={'label': 'Count'}\n",
    "            )\n",
    "            plt.title(f'Confusion Matrix: {self.best_model_name}', fontsize=14, fontweight='bold')\n",
    "            plt.ylabel('True Label', fontsize=12)\n",
    "            plt.xlabel('Predicted Label', fontsize=12)\n",
    "            \n",
    "            # Add percentages\n",
    "            total = cm.sum()\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    pct = (cm[i, j] / total) * 100\n",
    "                    plt.text(j + 0.5, i + 0.7, f'({pct:.1f}%)', \n",
    "                            ha='center', va='center', fontsize=10, color='gray')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{viz_dir}/confusion_matrix_best.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(\"  âœ“ Saved confusion matrix\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Error plotting confusion matrix: {e}\")\n",
    "\n",
    "        # 2. ROC Curves for all models\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            for name, res in self.results.items():\n",
    "                if res['y_prob_test'] is not None:\n",
    "                    fpr, tpr, _ = roc_curve(self.y_test, res['y_prob_test'])\n",
    "                    auc = res['roc_auc']\n",
    "                    \n",
    "                    linestyle = '-' if name == self.best_model_name else '--'\n",
    "                    linewidth = 3 if name == self.best_model_name else 2\n",
    "                    \n",
    "                    plt.plot(fpr, tpr, linestyle=linestyle, linewidth=linewidth,\n",
    "                            label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random (AUC = 0.500)')\n",
    "            plt.xlabel('False Positive Rate', fontsize=12)\n",
    "            plt.ylabel('True Positive Rate', fontsize=12)\n",
    "            plt.title('ROC Curves - All Models', fontsize=14, fontweight='bold')\n",
    "            plt.legend(loc='lower right', fontsize=10)\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{viz_dir}/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(\"  âœ“ Saved ROC curves\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Error plotting ROC curves: {e}\")\n",
    "\n",
    "        # 3. Model Comparison Bar Chart\n",
    "        try:\n",
    "            metrics_data = []\n",
    "            for name, res in self.results.items():\n",
    "                metrics_data.append({\n",
    "                    'Model': name,\n",
    "                    'Accuracy': res['test_accuracy'],\n",
    "                    'Precision': res['precision'],\n",
    "                    'Recall': res['recall'],\n",
    "                    'F1-Score': res['f1_score']\n",
    "                })\n",
    "\n",
    "            df_metrics = pd.DataFrame(metrics_data)\n",
    "            df_melted = df_metrics.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            sns.barplot(data=df_melted, x='Model', y='Score', hue='Metric')\n",
    "            plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Model', fontsize=12)\n",
    "            plt.ylabel('Score', fontsize=12)\n",
    "            plt.ylim(0, 1.05)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.legend(title='Metric', loc='lower right')\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{viz_dir}/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(\"  âœ“ Saved model comparison chart\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Error plotting model comparison: {e}\")\n",
    "\n",
    "        # 4. Feature Importance (if available)\n",
    "        try:\n",
    "            if hasattr(self.best_model, 'feature_importances_'):\n",
    "                importances = self.best_model.feature_importances_\n",
    "                indices = np.argsort(importances)[-20:]  # Top 20\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.barh(range(len(indices)), importances[indices])\n",
    "                plt.yticks(range(len(indices)), [self.feature_names[i] for i in indices])\n",
    "                plt.xlabel('Importance', fontsize=12)\n",
    "                plt.title(f'Top 20 Feature Importances: {self.best_model_name}', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{viz_dir}/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(\"  âœ“ Saved feature importance chart\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Feature importance not available\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    def save_best_model(self):\n",
    "        \"\"\"Save the best model and ALL related artifacts (CRITICAL FOR APP)\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"SAVING BEST MODEL AND ARTIFACTS\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # 1. Save model with generic name (for easy loading in apps)\n",
    "        generic_path = f'{self.output_dir}/best_model.pkl'\n",
    "        joblib.dump(self.best_model, generic_path)\n",
    "        print(f\"  âœ“ Best model saved: {generic_path}\")\n",
    "\n",
    "        # 2. Save model with specific name (for backup/version control)\n",
    "        specific_name = self.best_model_name.replace(\" \", \"_\").lower()\n",
    "        specific_path = f'{self.output_dir}/model_{specific_name}.pkl'\n",
    "        joblib.dump(self.best_model, specific_path)\n",
    "        print(f\"  âœ“ Backup saved: {specific_path}\")\n",
    "\n",
    "        # 3. Save feature names (CRITICAL FOR APP INPUTS)\n",
    "        if self.feature_names:\n",
    "            features_path = f'{self.output_dir}/feature_names.json'\n",
    "            with open(features_path, 'w') as f:\n",
    "                json.dump(self.feature_names, f, indent=2)\n",
    "            print(f\"  âœ“ Feature names saved: {features_path}\")\n",
    "\n",
    "        # 4. Save model info text\n",
    "        info_path = f'{self.output_dir}/best_model_info.txt'\n",
    "        with open(info_path, 'w') as f:\n",
    "            res = self.results[self.best_model_name]\n",
    "            f.write(f\"Best Model: {self.best_model_name}\\n\")\n",
    "            f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            f.write(f\"Test Accuracy:  {res['test_accuracy']:.4f}\\n\")\n",
    "            f.write(f\"F1-Score:       {res['f1_score']:.4f}\\n\")\n",
    "            if res['cv_mean']:\n",
    "                f.write(f\"CV F1-Score:    {res['cv_mean']:.4f} (Â±{res['cv_std']:.4f})\\n\")\n",
    "\n",
    "        print(f\"  âœ“ Info saved: {info_path}\\n\")\n",
    "\n",
    "    def run_pipeline(self, specific_name=None):\n",
    "        \"\"\"Run the complete training pipeline\"\"\"\n",
    "        print(\"\\n\" + \"ğŸš€ STARTING MODEL TRAINING PIPELINE ğŸš€\".center(70))\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "\n",
    "        if not self.load_preprocessed_data(): return False\n",
    "        if not self.prepare_data(): return False\n",
    "        if not self.initialize_models(): return False\n",
    "        if not self.train_and_evaluate_models(): return False\n",
    "\n",
    "        self.compare_models()\n",
    "        self.generate_detailed_report()\n",
    "        self.plot_visualizations()\n",
    "        self.save_best_model()\n",
    "\n",
    "        duration = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "        print(\"=\"*70)\n",
    "        print(\"âœ… TRAINING COMPLETED SUCCESSFULLY! âœ…\".center(70))\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nExecution time: {duration:.1f} seconds\")\n",
    "        print(f\"\\nOutput files created in {self.output_dir}/:\")\n",
    "        print(f\"  ğŸ“ best_model.pkl\")\n",
    "        print(f\"  ğŸ“ model_{specific_name}.pkl\")\n",
    "        print(f\"  ğŸ“ feature_names.json\")\n",
    "        print(f\"  ğŸ“ best_model_info.txt\")\n",
    "        print(f\"  ğŸ“ best_model_metrics.json\")\n",
    "        print(f\"  ğŸ“ model_comparison.csv\")\n",
    "        print(f\"  ğŸ“ visualizations/\")\n",
    "        print(f\"  ğŸ“ reports/\")\n",
    "        print()\n",
    "        return True\n",
    "\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure this matches your file path\n",
    "    PREPROCESSED_DATA = \"data/processed/preprocessed_data.csv\"\n",
    "    \n",
    "    trainer = DepressionModelTrainer(PREPROCESSED_DATA)\n",
    "    trainer.run_pipeline()"
   ],
   "id": "c8e3bb02385f90c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Output directories created\n",
      "\n",
      "                 ğŸš€ STARTING MODEL TRAINING PIPELINE ğŸš€                 \n",
      "\n",
      "======================================================================\n",
      "LOADING PREPROCESSED DATA\n",
      "======================================================================\n",
      "âœ“ Data loaded successfully\n",
      "  Shape: (27901, 63)\n",
      "  Columns: 63\n",
      "\n",
      "  Target Distribution (Depression):\n",
      "    Healthy (No Depression) (0): 11,565 samples (41.5%)\n",
      "    Depressed (1): 16,336 samples (58.5%)\n",
      "\n",
      "======================================================================\n",
      "PREPARING DATA FOR TRAINING\n",
      "======================================================================\n",
      "  Features: 62 columns\n",
      "  Samples: 27,901\n",
      "\n",
      "  Train/Test Split:\n",
      "    Train set: 22,320 samples (80%)\n",
      "    Test set:  5,581 samples (20%)\n",
      "\n",
      "  Train distribution:\n",
      "    Class 0: 9,252 (41.5%)\n",
      "    Class 1: 13,068 (58.5%)\n",
      "\n",
      "  Test distribution:\n",
      "    Class 0: 2,313 (41.4%)\n",
      "    Class 1: 3,268 (58.6%)\n",
      "\n",
      "======================================================================\n",
      "INITIALIZING MODELS\n",
      "======================================================================\n",
      "  Initialized 7 models:\n",
      "    â€¢ Logistic Regression\n",
      "    â€¢ Random Forest\n",
      "    â€¢ Gradient Boosting\n",
      "    â€¢ Support Vector Machine\n",
      "    â€¢ K-Nearest Neighbors\n",
      "    â€¢ Decision Tree\n",
      "    â€¢ Naive Bayes\n",
      "\n",
      "======================================================================\n",
      "TRAINING AND EVALUATING MODELS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MODEL: Logistic Regression\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:   84.64%\n",
      "  Test Accuracy:    84.29%\n",
      "  Precision:        84.46%\n",
      "  Recall:           84.29%\n",
      "  F1-Score:         84.34%\n",
      "  ROC-AUC:          91.82%\n",
      "  CV F1-Score:      84.53% (Â±0.22%)\n",
      "  CV Scores:       ['84.76%', '84.73%', '84.44%', '84.57%', '84.17%']\n",
      "  Overfit Gap:       0.35%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  79.55%\n",
      "    Recall:     83.57%\n",
      "    F1-Score:   81.51%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  87.94%\n",
      "    Recall:     84.79%\n",
      "    F1-Score:   86.34%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      1933      380\n",
      "    Depressed     497     2771\n",
      "\n",
      "======================================================================\n",
      "MODEL: Random Forest\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:   86.94%\n",
      "  Test Accuracy:    83.57%\n",
      "  Precision:        83.73%\n",
      "  Recall:           83.57%\n",
      "  F1-Score:         83.62%\n",
      "  ROC-AUC:          91.58%\n",
      "  CV F1-Score:      83.92% (Â±0.37%)\n",
      "  CV Scores:       ['84.24%', '83.49%', '84.19%', '84.24%', '83.44%']\n",
      "  Overfit Gap:       3.37%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  78.84%\n",
      "    Recall:     82.49%\n",
      "    F1-Score:   80.63%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  87.19%\n",
      "    Recall:     84.33%\n",
      "    F1-Score:   85.74%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      1908      405\n",
      "    Depressed     512     2756\n",
      "\n",
      "======================================================================\n",
      "MODEL: Gradient Boosting\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:   86.76%\n",
      "  Test Accuracy:    84.57%\n",
      "  Precision:        84.52%\n",
      "  Recall:           84.57%\n",
      "  F1-Score:         84.52%\n",
      "  ROC-AUC:          91.82%\n",
      "  CV F1-Score:      84.39% (Â±0.36%)\n",
      "  CV Scores:       ['84.93%', '84.33%', '84.55%', '84.30%', '83.83%']\n",
      "  Overfit Gap:       2.18%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  82.79%\n",
      "    Recall:     79.25%\n",
      "    F1-Score:   80.98%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  85.74%\n",
      "    Recall:     88.34%\n",
      "    F1-Score:   87.02%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      1833      480\n",
      "    Depressed     381     2887\n",
      "\n",
      "======================================================================\n",
      "MODEL: Support Vector Machine\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:   85.85%\n",
      "  Test Accuracy:    84.18%\n",
      "  Precision:        84.36%\n",
      "  Recall:           84.18%\n",
      "  F1-Score:         84.23%\n",
      "  ROC-AUC:          91.63%\n",
      "  CV F1-Score:      84.13% (Â±0.45%)\n",
      "  CV Scores:       ['84.23%', '83.65%', '84.59%', '84.62%', '83.57%']\n",
      "  Overfit Gap:       1.67%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  79.40%\n",
      "    Recall:     83.48%\n",
      "    F1-Score:   81.39%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  87.87%\n",
      "    Recall:     84.67%\n",
      "    F1-Score:   86.24%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      1931      382\n",
      "    Depressed     501     2767\n",
      "\n",
      "======================================================================\n",
      "MODEL: K-Nearest Neighbors\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:  100.00%\n",
      "  Test Accuracy:    81.62%\n",
      "  Precision:        81.56%\n",
      "  Recall:           81.62%\n",
      "  F1-Score:         81.46%\n",
      "  ROC-AUC:          88.53%\n",
      "  CV F1-Score:      81.73% (Â±0.44%)\n",
      "  CV Scores:       ['81.64%', '82.07%', '82.34%', '81.56%', '81.06%']\n",
      "  Overfit Gap:      18.38%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  80.66%\n",
      "    Recall:     73.19%\n",
      "    F1-Score:   76.75%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  82.19%\n",
      "    Recall:     87.58%\n",
      "    F1-Score:   84.80%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      1693      620\n",
      "    Depressed     406     2862\n",
      "\n",
      "âš ï¸  WARNING: Possible overfitting detected!\n",
      "   Train-Test gap: 18.38%\n",
      "\n",
      "======================================================================\n",
      "MODEL: Decision Tree\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:   89.54%\n",
      "  Test Accuracy:    78.77%\n",
      "  Precision:        79.00%\n",
      "  Recall:           78.77%\n",
      "  F1-Score:         78.84%\n",
      "  ROC-AUC:          84.87%\n",
      "  CV F1-Score:      79.66% (Â±0.36%)\n",
      "  CV Scores:       ['79.75%', '79.07%', '79.96%', '79.46%', '80.05%']\n",
      "  Overfit Gap:      10.77%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  73.10%\n",
      "    Recall:     77.17%\n",
      "    F1-Score:   75.08%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  83.18%\n",
      "    Recall:     79.90%\n",
      "    F1-Score:   81.50%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      1785      528\n",
      "    Depressed     657     2611\n",
      "\n",
      "âš ï¸  WARNING: Possible overfitting detected!\n",
      "   Train-Test gap: 10.77%\n",
      "\n",
      "======================================================================\n",
      "MODEL: Naive Bayes\n",
      "======================================================================\n",
      "Training...\n",
      "Performing 5-Fold Cross-Validation...\n",
      "\n",
      "ğŸ“Š PERFORMANCE METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Train Accuracy:   41.57%\n",
      "  Test Accuracy:    41.50%\n",
      "  Precision:        56.22%\n",
      "  Recall:           41.50%\n",
      "  F1-Score:         24.50%\n",
      "  ROC-AUC:          84.80%\n",
      "  CV F1-Score:      24.60% (Â±0.10%)\n",
      "  CV Scores:       ['24.51%', '24.79%', '24.54%', '24.64%', '24.54%']\n",
      "  Overfit Gap:       0.07%\n",
      "\n",
      "ğŸ“ˆ PER-CLASS METRICS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Class 0 (Healthy):\n",
      "    Precision:  41.46%\n",
      "    Recall:     99.87%\n",
      "    F1-Score:   58.59%\n",
      "\n",
      "  Class 1 (Depressed):\n",
      "    Precision:  66.67%\n",
      "    Recall:      0.18%\n",
      "    F1-Score:    0.37%\n",
      "\n",
      "ğŸ¯ CONFUSION MATRIX:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                Predicted\n",
      "              Healthy  Depressed\n",
      "    Healthy      2310        3\n",
      "    Depressed    3262        6\n",
      "\n",
      "\n",
      "âœ“ Successfully trained 7/7 models\n",
      "\n",
      "======================================================================\n",
      "FINAL MODEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Model                       Accuracy   F1-Score  Precision     Recall      CV F1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Gradient Boosting             84.57%     84.52%     84.52%     84.57%     84.39%\n",
      "Logistic Regression           84.29%     84.34%     84.46%     84.29%     84.53%\n",
      "Support Vector Machine        84.18%     84.23%     84.36%     84.18%     84.13%\n",
      "Random Forest                 83.57%     83.62%     83.73%     83.57%     83.92%\n",
      "K-Nearest Neighbors           81.62%     81.46%     81.56%     81.62%     81.73%\n",
      "Decision Tree                 78.77%     78.84%     79.00%     78.77%     79.66%\n",
      "Naive Bayes                   41.50%     24.50%     56.22%     41.50%     24.60%\n",
      "\n",
      "======================================================================\n",
      "ğŸ† BEST MODEL: Gradient Boosting\n",
      "======================================================================\n",
      "  Test Accuracy:   84.57%\n",
      "  F1-Score:        84.52%\n",
      "  Precision:       84.52%\n",
      "  Recall:          84.57%\n",
      "  ROC-AUC:         91.82%\n",
      "  CV F1-Score:     84.39% (Â±0.36%)\n",
      "\n",
      "âœ“ Comparison saved to: models/model_comparison.csv\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING DETAILED REPORT\n",
      "======================================================================\n",
      "\n",
      "Classification Report for Gradient Boosting:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy     0.8279    0.7925    0.8098      2313\n",
      "   Depressed     0.8574    0.8834    0.8702      3268\n",
      "\n",
      "    accuracy                         0.8457      5581\n",
      "   macro avg     0.8427    0.8379    0.8400      5581\n",
      "weighted avg     0.8452    0.8457    0.8452      5581\n",
      "\n",
      "âœ“ Report saved to: models/reports/classification_report.txt\n",
      "âœ“ Metrics saved to: models/best_model_metrics.json\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "======================================================================\n",
      "  âœ“ Saved confusion matrix\n",
      "  âœ“ Saved ROC curves\n",
      "  âœ“ Saved model comparison chart\n",
      "  âœ“ Saved feature importance chart\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SAVING BEST MODEL AND ARTIFACTS\n",
      "======================================================================\n",
      "  âœ“ Best model saved: models/best_model.pkl\n",
      "  âœ“ Backup saved: models/model_gradient_boosting.pkl\n",
      "  âœ“ Feature names saved: models/feature_names.json\n",
      "  âœ“ Info saved: models/best_model_info.txt\n",
      "\n",
      "======================================================================\n",
      "                 âœ… TRAINING COMPLETED SUCCESSFULLY! âœ…                 \n",
      "======================================================================\n",
      "\n",
      "Execution time: 350.0 seconds\n",
      "\n",
      "Output files created in models/:\n",
      "  ğŸ“ best_model.pkl\n",
      "  ğŸ“ model_None.pkl\n",
      "  ğŸ“ feature_names.json\n",
      "  ğŸ“ best_model_info.txt\n",
      "  ğŸ“ best_model_metrics.json\n",
      "  ğŸ“ model_comparison.csv\n",
      "  ğŸ“ visualizations/\n",
      "  ğŸ“ reports/\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
